#!/bin/bash

#BSUB -P AST136
#BSUB -W 0:01
#BSUB -nnodes 1
#BSUB -alloc_flags smt1
#BSUB -J sedovGpuCpp
#BSUB -o sedovGpuCpp.%J
#BSUB -e sedovGpuCpp.%J
 
######################################################################
#####-----              FULLY SPECIFY TEST RUN              -----#####
######################################################################
# IMPORTANT: Match this to X in smtX BSUB statment above
N_HYPERTHREADS_PER_CORE=1

# This should match the SW stack used to build the test binaries
# as specified in buildSedovGpuCpp.sh when the binary to be used here was
# built
. $RUNTIME_PGI_SETUP

######################################################################
#####-----             DO NOT ALTER LINES BELOW             -----#####
######################################################################
module list

# Fixed hardware information
N_SOCKET_PER_NODE=2
N_GPU_PER_SOCKET=3

# Resource Set - Use all resources so that we can compare against a
#                CPU run using all node resources
N_PROC_PER_RS=1
N_GPU_PER_PROC=1
N_CORES_PER_PROC=7
N_RS_PER_SOCKET=3
N_RS_PER_NODE=$(($N_RS_PER_SOCKET * $N_SOCKET_PER_NODE))

# Dynamically determine the number of nodes from LSF env var
# The host output contains the word batch1 and repeats of the hosts names
N_HOST_LINES=$(echo $LSB_HOSTS | tr ' ' '\n' | sort -u | wc -l)
N_NODES=$(($N_HOST_LINES - 1))

# Derived results
N_TOTAL_RS=$(($N_NODES * $N_RS_PER_NODE))
N_GPU_PER_RS=$(($N_GPU_PER_PROC * $N_PROC_PER_RS))
N_CORES_PER_RS=$(($N_CORES_PER_PROC * $N_PROC_PER_RS))
N_THREADS_PER_PROC=$(($N_HYPERTHREADS_PER_CORE * $N_CORES_PER_PROC))

# No need for OpenMP
export OMP_NUM_THREADS=1

echo "---------------------------------------------------------------------"
echo "Number of Nodes               = $N_NODES"
echo "Number of RS Per Node         = $N_RS_PER_NODE"
echo "Number of Resource Sets (RS)  = $N_TOTAL_RS"
echo "Number of Processes per RS    = $N_PROC_PER_RS"
echo "Number of GPU per Process     = $N_GPU_PER_PROC"
echo "Number of Cores per Process   = $N_CORES_PER_PROC"
echo "Number of HW Threads per Core = $N_HYPERTHREADS_PER_CORE"
echo "Number of Threads per Process = $N_THREADS_PER_PROC"
echo "---------------------------------------------------------------------"

binary=$LS_SUBCWD/binaries/sedov_gpu_cpp.x

folder=/gpfs/alpine/scratch/joneal/ast136/OrchestrationRuntime/sedovGpuCpp_$LSB_JOBID
mkdir -p $folder ; cd $folder

date
echo $binary
echo
ldd $binary
echo
time jsrun -n $N_RS_PER_NODE \
           -r $N_RS_PER_NODE \
           -a $N_PROC_PER_RS \
           -c $N_CORES_PER_RS \
           -g $N_GPU_PER_RS \
           -l CPU-CPU -d cyclic -b rs \
           nvprof -o sedovGpuCpp.%h.%p $binary

#time jsrun -n $N_RS_PER_NODE \
#           -r $N_RS_PER_NODE \
#           -a $N_PROC_PER_RS \
#           -c $N_CORES_PER_RS \
#           -g $N_GPU_PER_RS \
#           -l CPU-CPU -d cyclic -b rs \
#           $binary

